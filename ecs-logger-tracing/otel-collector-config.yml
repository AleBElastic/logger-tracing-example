receivers:
  # Receiver for docker specific log files
  filelog/docker:
    include_file_path: true
    include:
     -     /hostfs/var/lib/docker/containers/ff2961e131e57d03536cb506cfbd4978654a30039d18c3ba0c99bddbac1b5b50/*.log
    retry_on_failure:
      enabled: true
    start_at: end
    storage: file_storage
    operators:
      # Step 1: Parse the outer JSON created by the Docker json-file log driver.
      - type: json_parser
        parse_from: body
        parse_to: attributes
      - type: json_parser
        parse_from: attributes.log
        parse_to: attributes
    # While parsing, immediately handle the timestamp and severity.
        timestamp:
          parse_from: attributes["@timestamp"]
          layout: '%Y-%m-%dT%H:%M:%S.%fZ'
        severity:
          parse_from: attributes["log.level"]
        message:
          parse_from: attributes["log"]
      - type: move
        from: attributes.message
        to: body

  docker_stats:
    endpoint: "unix:///var/run/docker.sock" # Default socket path
    collection_interval: 1s # How often to scrape metrics
    # Other configuration options for specific metrics or filters go here

  # Receiver for CPU, Disk, Memory, and Filesystem metrics
  hostmetrics/system:
    collection_interval: 1s
    scrapers:
      disk:
      filesystem:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
          system.cpu.logical.count:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      # process scraper is disabled for now: https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/39423
      #process:
      #  mute_process_exe_error: true
      #  mute_process_io_error: true
      #  mute_process_user_error: true
      #  metrics:
      #    process.threads:
      #      enabled: true
      #    process.open_file_descriptors:
      #      enabled: true
      #    process.memory.utilization:
      #      enabled: true
      #    process.disk.operations:
      #      enabled: true
      network:
      processes:
      load:

extensions:
  file_storage:
    directory: ${env:STORAGE_DIR}

processors:
  resourcedetection:
    detectors: ["system"]
    system:
      hostname_sources: ["os"]
      resource_attributes:
        host.name:
          enabled: true
        host.id:
          enabled: false
        host.arch:
          enabled: true
        host.ip:
          enabled: true
        host.mac:
          enabled: true
        host.cpu.vendor.id:
          enabled: true
        host.cpu.family:
          enabled: true
        host.cpu.model.id:
          enabled: true
        host.cpu.model.name:
          enabled: true
        host.cpu.stepping:
          enabled: true
        host.cpu.cache.l2.size:
          enabled: true
        os.description:
          enabled: true
        os.type:
          enabled: true
 
exporters:

  # Exporter to send logs and metrics to Elasticsearch Managed OTLP Input
  otlp/ingest:
    endpoint: ${env:ELASTIC_OTLP_ENDPOINT}
    headers:
      Authorization: ApiKey ${env:ELASTIC_API_KEY}

service:
  extensions: [file_storage]
  pipelines:
    metrics/hostmetrics:
      receivers: [hostmetrics/system]
      processors: [resourcedetection]
      exporters: [otlp/ingest]
    logs/docker:
      receivers: [filelog/docker]
      processors: [resourcedetection]
      exporters: [otlp/ingest]
    metrics/docker_stats:
      receivers: [docker_stats]
      processors: [resourcedetection]
      exporters: [otlp/ingest]
